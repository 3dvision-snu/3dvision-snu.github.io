---
title: "3D Vision Lab - Research"
layout: textlay
excerpt: "3D Vision Lab -- Research"
sitemap: false
permalink: /research/
---

## Research
<br>

[comment]: <> (We strive to the emerging field of 3D vision where we understand the 3D world around us. We not only sense, acquire and perceive the 3D models, but also visualize and extract semantic information to develop various applications, namely VR/AR, robotics, human augmentation, and ambient intelligence to name a few. The ultimate goal is the bridge between human and intelligent agent to benefit human.)
We strive to the emerging field of 3D vision where we understand the 3D world around us. With the help of various acquisition devices, we can capture or infer a 3D model of objects, scenes, and human bodies. We can visualize the 3D model and extract semantic information to develop various applications, namely VR/AR, robotics, human augmentation, and ambient intelligence to name a few. The ultimate goal is the bridge between human and intelligent agent to benefit human.

### Research projects include: <br>
#### 1) 3D for perception (computer vision) <br>
> <small> <span style="color:dimgrey">3D information is widely used for perception, and recent trends on 3D perception utilize the state-of-the-art techniques from computer vision and machine learning. We utilize neural networks of generative models, metric learning, and/or reinforcement learning to boost the performance. </span> </small> <br>
![]({{ site.url }}{{ site.baseurl }}/images/respic/perception_211011.png){: style="width: 100%; border: 10px"}<br>

#### 2) 3D for visualization (graphics, AR/VR) <br>
> <small> <span style="color:dimgrey"> 3D models are crucial for seamless AR/VR applications and realistic rendering. The key technical components include localization, pose estimation, texture and material acquisition, and lighting estimation.</span> </small> <br>
![]({{ site.url }}{{ site.baseurl }}/images/respic/visualization_211011.png){: style="width: 100%; border: 10px"}<br>

[comment]: <> (<p align="center">)

[comment]: <> (  <img width=700 height=346 src="{{ site.url }}{{ site.baseurl }}/images/respic/visualization_211011.png">)

[comment]: <> (</p>)

#### 3) 3D for Interaction (robotics, animation) <br>
> <small> <span style="color:dimgrey"> The real-world 3D models are utilized for manipulation, navigation, or other robotic applications. Also, various physical interactions with 3D scenes are tightly coupled with the actions of humans or robots in addition to the physical properties of individual objects. Our focus is to build algorithms to control robot in un-constrained set-up and generate natural interaction to reflect the real-world scenarios.</span> </small> <br>
![]({{ site.url }}{{ site.baseurl }}/images/respic/interaction_211011.png){: style="width: 100%; border: 10px"}<br>


[comment]: <> (![]&#40;{{ site.url }}{{ site.baseurl }}/images/respic/perception_211011.png&#41;{: style="width: 100%; border: 10px"}<br>)

[comment]: <> (**Light-Weight Update of Large- Scale 3D Scenes**<br>)

[comment]: <> (<U>Research objective</U>: Given off-line 3D scan and online 360 photo, quickly update the 3D model of the scene.<br>)

[comment]: <> (<U>Approach</U>: Hybrid feature matching of different data modality for localization, the change detection of 360 images with respect to the large- scale 3D model.<br>)

[comment]: <> (![]&#40;{{ site.url }}{{ site.baseurl }}/images/respic/image003.png&#41;{: style="width: 300px; border: 10px"}<br>)

[comment]: <> (**Real-Time 3D Video Streaming System**<br>)

[comment]: <> (<U>Research objective</U>: Streaming volumetric video at video frame rate via mobile devices<br>)

[comment]: <> (<U>Research scope</U>: Efficient storing and processing with dynamic octree structure, adaptive rendering resolution and view-point prediction<br><br>)

[comment]: <> (**2&#41; Using 3D models for visualization:**{: style="font-size: 110%" } 3D models are crucial for seamless AR/VR applications and realistic rendering. The key technical components include localization, pose estimation, texture acquisition, and lighting estimation.<br>)

[comment]: <> (![]&#40;{{ site.url }}{{ site.baseurl }}/images/respic/image004.jpg&#41;{: style="width: 300px; border: 10px"}<br>)

[comment]: <> (![]&#40;{{ site.url }}{{ site.baseurl }}/images/respic/image005.png&#41;{: style="width: 300px; border: 10px"}<br>)

[comment]: <> (**Novel View Synthesis**<br>)

[comment]: <> (<U>Research objective</U>: Synthesize a target view from a given source view and its camera pose without a 3D model, Extend the latent space representation into multi-object 3D scenes<br>)

[comment]: <> (<U>Approach</U>: Neural rending with end-to-end trainable framework<br><br>)

[comment]: <> (**3&#41; Using 3D data for perception:**{: style="font-size: 110%" } 3D information is widely used for perception, and recent trends on 3D perception utilize the state-of-the-art techniques from computer vision and machine learning. We utilize neural networks of generative models, metric learning, and/or reinforcement learning to boost the performance.<br>)

[comment]: <> (![]&#40;{{ site.url }}{{ site.baseurl }}/images/respic/image006.jpg&#41;{: style="width: 300px; border: 10px"}<br>)

[comment]: <> (![]&#40;{{ site.url }}{{ site.baseurl }}/images/respic/image007.png&#41;{: style="width: 300px; border: 10px"}<br>)

[comment]: <> (**Shape Completion Preserving Details**<br>)

[comment]: <> (<U>Motivation</U>: Existing 3D data suffer from occlusion and noise of sensors. Current shape completion pipeline acts as object recognition<br>)

[comment]: <> (<U>Approach</U>: Train GAN in local and global shape and use graph-based convolutional network to preserve details<br>)

[comment]: <> (![]&#40;{{ site.url }}{{ site.baseurl }}/images/respic/image008.png&#41;{: style="width: 300px; border: 10px"}<br>)

[comment]: <> (**Point Cloud Instance Segmentation**<br>)

[comment]: <> (<U>Research objective</U>: Direct segmentation of individual objects on the raw 3D measurements<br>)

[comment]: <> (<U>Approach</U>: Deep metric learning on point cloud feature extracted via sparse convolutional neural network<br><br>)

[comment]: <> (**4&#41; Using 3D information for interaction**:  The real-world 3D models are utilized for manipulation, navigation, or other robotic applications. Our focus is to build algorithms to control robot in un-constrained set-up and robust to small changes.)

[comment]: <> (![]&#40;{{ site.url }}{{ site.baseurl }}/images/respic/image009.png&#41;{: style="width: 300px; border: 10px"}<br>)

[comment]: <> (**Visuomotor Policy via Scene Understanding**<br>)

[comment]: <> (<U>Research objective</U>: Given complex visual scene, make robot disentangle raw observation into latent full state, and learn generalized policy.<br>)

[comment]: <> (<U>Research scope</U>: Robot manipulation in non-stationary environment based on 2D/3D raw observation<br>)

[comment]: <> (![]&#40;{{ site.url }}{{ site.baseurl }}/images/respic/image010.png&#41;{: style="width: 300px; border: 10px"}<br>)

[comment]: <> (**Occlusion-Aware Navigation**<br>)

[comment]: <> (<U>Research objective</U>: Given an approximate map of changing environment, infer the navigation path allowing online modification<br>)

[comment]: <> (<U>Research scope</U>: Scene understanding from partial observation, joint inference of human-object interaction and scene reconstruction<br><br>)